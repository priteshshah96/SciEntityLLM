Is it possible to use out-of-domain acoustic training data to improve a speech recognizer's performance on a speciic, independent application? In our experiments, we use Wallstreet Journal (WSJ) data to train a recognizer, which is adapted and evaluated in the Phonebook domain. Apart from their common language (US English), the two corpora diier in many important respects: microphone vs. telephone channel, continuous speech vs. isolated words, mismatch i n s p e a k i n g r a t e. This paper deals with two questions. First, starting from the WSJ-trained recognizer, how much adaptation data (taken from the Phonebook training corpus) is necessary to achieve a reasonable recognition performance in spite of the high degree of mismatch? Second, is it possible to improve the recognition performance of a Phonebook-trained baseline acoustic model by using additional out-of-domain training data? The paper describes the adaptation and normalization techniques used to bridge the mismatch b e-tween the two corpora.