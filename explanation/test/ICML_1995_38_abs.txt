An important area of learning in autonomous agents is the ability to learn domain-speciic models of actions to be used by planning systems. In this paper, we present methods by which an agent learns action models from its own experience and from its observation of a domain expert. These methods diier from previous work in the area in two ways: the use of an action model formalism which is better suited to the needs of a re-active agent, and successful implementation of noise-handling mechanisms. Training instances are generated from experience and observation, and a variant of GOLEM is used to learn action models from these instances. The integrated learning system has been experimentally validated in simulated construction and ooce domains.